{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tensorflow.keras import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import datasets, layers, models, losses\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test)=tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize images for vgg19\n",
    "import cv2\n",
    "\n",
    "def resize(img_array):\n",
    "    tmp = np.empty((img_array.shape[0], IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    for i in range(len(img_array)):\n",
    "        img = img_array[i].reshape(28, 28).astype('uint8')\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        img = img.astype('float32')/255\n",
    "        tmp[i] = img\n",
    "        \n",
    "    return tmp\n",
    "\n",
    "train_x_resize = resize(x_train)\n",
    "test_x_resize = resize(x_test)\n",
    "print(train_x_resize.shape)\n",
    "print(test_x_resize.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_final = np.stack((train_x_resize,)*3, axis=-1)\n",
    "test_x_final = np.stack((test_x_resize,)*3, axis=-1)\n",
    "print(train_x_final.shape)\n",
    "print(test_x_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_x_final, y_train, test_size=0.2, random_state=2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(6, 5, activation='tanh', input_shape=x_train.shape[1:]))\n",
    "model.add(layers.AveragePooling2D(2))\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "model.add(layers.Conv2D(16, 5, activation='tanh'))\n",
    "model.add(layers.AveragePooling2D(2))\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "model.add(layers.Conv2D(120, 5, activation='tanh'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(84, activation='tanh'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss=losses.sparse_categorical_crossentropy, \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earl = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, \n",
    "                    y_train, \n",
    "                    batch_size=64, \n",
    "                    epochs=20, \n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[earl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(15,15))  \n",
    "axs[0].plot(history.history['loss']) \n",
    "axs[0].plot(history.history['val_loss']) \n",
    "axs[0].title.set_text('Training Loss vs Validation Loss') \n",
    "axs[0].legend(['Train', 'Val'])  \n",
    "axs[1].plot(history.history['accuracy']) \n",
    "axs[1].plot(history.history['val_accuracy']) \n",
    "axs[1].title.set_text('Training Accuracy vs Validation Accuracy') \n",
    "axs[1].legend(['Train', 'Val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8851e664df791c63fc314e054a392625d7940ac72e9fc31c8a07f6c226ae09dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
